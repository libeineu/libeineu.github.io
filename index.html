<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Bei Li</title>
  
  <meta name="author" content="Bei Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <!-- <p>[<a href="index_cn.html">‰∏≠Êñá‰∏ªÈ°µ</a>]</p>  -->
                <name>Bei Li</name>  
                
              </p>
              <p>I have already obtained my Ph.D degree from the Department of <a href="http://www.cse.neu.edu.cn/">Computer Science and Technology</a> at <a href="http://www.neu.edu.cn/"> Northeastern University</a>, China. I work at <a href="https://www.nlplab.com/">Natural Language Processing Lab </a> under the supervision of Prof. <a href="https://www.nlplab.com/members/xiaotong.html">Tong Xiao</a> and Prof. <a href="https://www.nlplab.com/members/zhujingbo.html"> Jingbo Zhu</a>.
              </p>
              <p>
                I received my bachelor degree in 2017 from Northeastern University, majoring in Computer Science and Technology, and my master in 2020 from Northeastern University, majoring in Computer Software and Theory.     
              </p>
              <p>
                My research interests include complex architecture modeling, deep transformers, multimodal modeling, and machine learning. Currently, I am focusing on large language models, such as prompt engineering via deliberation (DTG), evolutionary algorithms-based prompt search (EvoPrompt), foundation models (PCformer and its subsequent work), and DPO improvements (temporal-decay based DPO). Please feel free to contact me if you are interested in my work or have any questions you'd like to discuss!
              </p>
              <p style="text-align:center">
                <a href="libei_neu@outlook.com">Email</a> &nbsp/&nbsp
                <a href="data/cv.pdf">Resume</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=wzbJ5EIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/libeineu/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/LiBei.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/libei.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Research</heading>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p>
                My primary focus lies within the domain of sequence generation tasks, encompassing fields such as machine translation, abstractive summarization, and more. Presently, my central research objective is the development of parameter-efficient backbones for natural language processing tasks, striving towards models that achieve superior performance with a minimized computational footprint. While, I am also interested in designing highly effective prompts for large language model to activate the underlying abilities. 

              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>News</heading>
            <ul>
              <li>
                [Jan'2025] <strong>One</strong> paper accepted by <a href="https://iclr.cc/">ICLR 2025</a>.
              </li>
              <li>
                [Nov'2024] <strong>Two</strong> papers accepted by <a href="https://coling2025.org/">COLING 2025</a>.
              </li>
              <li>
                [Oct'2024] <strong>One</strong> paper accepted by <a href="https://neurips.cc/">NeurIPS 2024</a>.
              </li>
              <li>
                [Sep'2024] <strong>Five</strong> papers (5 main) accepted by <a href="https://2024.emnlp.org/">EMNLP 2024</a>.
              </li>
              <li>
                [May'2024] <strong>Three</strong> papers (1 main and 2 Findings) accepted by <a href="https://2024.aclweb.org/">ACL 2024</a>.
              </li>
              <li>
                [Dec'2023] <strong>One</strong> paper on automatic prompt search accepted by <a href="https://iclr.cc/">ICLR 2024</a>.
              </li>
              <li>
                [Dec'2023] <strong>One</strong> paper on speech translation accepted by <a href="https://2024.ieeeicassp.org/">ICASSP 2024</a>.
              </li>
              <li>
                [Dec'2023] <strong>One</strong> paper on RL sampling accepted by <a href="https://aaai.org/aaai-conference/">AAAI 2024</a>.
              </li>
              <li>
                [Oct'2023] <strong>Two</strong> papers (1 main and 1 Findings) accepted by <a href="https://2023.emnlp.org/">EMNLP 2023</a>.
              </li>
              <li>
                [May'2023] <strong>Three</strong> papers (1 main and 2 Findings) accepted by <a href="https://2023.aclweb.org/">ACL 2023</a>.
              </li>
              <li>
                [Dec'2022] Finished my internship at NLC, and start a new internship at Machine Learning Group (ML)</a>.
              </li>
              <li>
                [May'2022] Started my internship at MicroSoft Research Asia<a href="https://www.msra.cn/">(MSRA)</a>, Natural Language Computing (NLC).
              </li>
               <li>
                [Apr'2022] <strong>One</strong> paper on learning multiscale Transformer models for sequence generation accepted by <a href="https://icml.cc/Conferences/2022">ICML 2022</a>.
              </li>
              <li>
                [Feb'2022] <strong>Two</strong> papers on parameter-efficient backbone and multimodal machine translation accepted by <a href="https://www.2022.aclweb.org/">ACL 2022</a>.
              </li> 
              <li>
                [Apr'2021] <strong>One</strong> paper on knowledge distillation accepted to <a href="https://2021.aclweb.org/">ACL 2021</a>.
              </li>
              <li>
                [Nov'2020] <strong>One</strong> paper on deep Transformer compression accepted to <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.
              </li>
              <li>
                [Sep'2020] <strong>One</strong> paper on shallow-to-deep training for deep Transformer models accepted to <a href="https://2020.emnlp.org/">EMNLP 2020</a>.
              </li>
              <li>
                [Apr'2020] <strong>One</strong> paper on context-aware machine translation accepted to <a href="https://2020.aclweb.org/">ACL 2020</a>.
              </li>
              <li>
                [May'2019] <strong>One</strong> paper on the NiuTrans submission of WMT19 accepted to <a href="https://www.statmt.org/wmt19/">WMT 2019</a>.
              </li>
              <li>
                [May'2019] <strong>One</strong> paper on learning deep Transformer models accepted to <a href="https://2019.aclweb.org/">ACL 2019</a>.
              </li>
              

            </ul>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Publications</heading>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/NeurIPS2024.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Predictor-Corrector Enhanced Transformers with Exponential Moving Average Coefficient Learning</papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li</strong>, Tong Zheng, Rui Wang, Jiahao Liu, Qingyan Guo, Junliang Guo, Xu Tan, Tong Xiao, Jingbo Zhu, Jingang Wang and Xunliang Cai
              <br>
              <!-- <em>61th Annual Meeting of the Association for Computational Linguistics (<strong>Findings of ACL</strong>)</em>, 2023  -->
              <em>The Thirty-Eighth Annual Conference on Neural Information Processing Systems (<strong>Neurips</strong>)</em>, 2024
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2411.03042">[pdf]</a> / [<a href="">code</a>]
              <p></p>
              <p>
                In this work, we present a series of advanced explorations of Transformer architecture design to minimize the error compared to the true ``solution.'' First, we introduce a predictor-corrector learning framework to minimize truncation errors, which consists of a high-order predictor and a multistep corrector. Second, we propose an exponential moving average-based coefficient learning method to strengthen our higher-order predictor. Extensive experiments on large-scale machine translation, abstractive summarization, language modeling, and natural language understanding benchmarks demonstrate the superiority of our approach. On the WMT'14 English-German and English-French tasks, our model achieved BLEU scores of 30.95 and 44.27, respectively. Furthermore, on the OPUS multilingual machine translation task, our model surpasses a robust 3.8B DeepNet by an average of 2.9 SacreBLEU, using only 1/3 parameters. Notably, it also beats LLama models by 5.7 accuracy points on the LM Harness Evaluation.
              </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/ICLR2024.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Connecting large language models with evolutionary algorithms yields powerful prompt optimizers</papertitle>
              <!-- </a> -->
              <br>
              Qingyan Guo, Rui Wang, Junliang Guo, <strong>Bei Li</strong>, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang
              <br>
              <!-- <em>61th Annual Meeting of the Association for Computational Linguistics (<strong>Findings of ACL</strong>)</em>, 2023  -->
              <em>The Twelfth International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2309.08532">[pdf]</a> / [<a href="">code</a>]
              <p></p>
              <p>
                In this paper, we introduce EvoPrompt, a novel framework for optimizing discrete prompts in Large Language Models (LLMs) using evolutionary algorithms (EAs). This method effectively integrates the language processing strengths of LLMs with the optimization capabilities of EAs, eliminating the need for gradients or parameters. EvoPrompt starts with a set of prompts and evolves them through LLM-based iterations, showing significant improvement over human-crafted prompts and existing automated methods by up to 25% and 14% respectively. Tested on nine datasets across language understanding and generation tasks with both closed- and open-source LLMs like GPT-3.5 and Alpaca, EvoPrompt demonstrates the potential for further research in combining LLMs with traditional algorithms.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/EMNLP2023_mmt.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Incorporating Probing Signals into Multimodal Machine Translation via Visual Question-Answering Pairs.</papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li*</strong>, Yuxin Zuo*, Chuanhao Lv, Tong Zheng, Tong Xiao and Jingbo Zhu
              <br>
              <em>The 2023 Conference on Empirical Methods in Natural Language Processing (<strong>Findings of EMNLP</strong>)</em>, 2023 
              <br>
							<a href="#">[pdf]</a> / 
							<a href="#">[code]</a> 
							<!-- <a href="https://arxiv.org/abs/2305.19835">[pdf]</a> / [<a href="">code</a>] -->
              <p></p>
              <p>
                Building on our previous work presented at ACL 2022, this study aims to enhance cross-modal interaction in language models. We propose a new approach that generates Visual Question Answering (VQA)-style pairs from text and incorporates probing signals during the training process. Our extensive experiments confirm that this multi-task learning framework effectively alleviates the issue of insufficient cross-modal interaction, offering a significant advancement over our prior work.
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/EMNLP2023_main.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Rethinking and Improving Multi-task Learning for End-to-end Speech Translation</papertitle>
              <!-- </a> -->
              <br>
              Yuhao Zhang, Chen Xu, <strong>Bei Li</strong>,  Tong Xiao and Jingbo Zhu
              <br>
              <!-- <em>61th Annual Meeting of the Association for Computational Linguistics (<strong>Findings of ACL</strong>)</em>, 2023  -->
              <em>The 2023 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>)</em>, 2023
              <br>
							<a href="#">[pdf]</a> / 
							<a href="#">[code]</a> 
							<!-- <a href="https://arxiv.org/abs/2305.19835">[pdf]</a> / [<a href="">code</a>] -->
              <p></p>
              <p>
                In this work, we find that the textual encoder primarily facilitates cross-modal conversion, but the presence of noise in speech impedes the consistency between text and speech representations. Furthermore, we propose an improved multi-task learning (IMTL) approach for the ST task, which bridges the modal gap by mitigating the difference in length and representation.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/Neurips_submission.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Deliberate then Generate: Enhanced Prompting Framework for Text Generation</papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li</strong>, Rui Wang, Junliang Guo, Kaitao Song, Xu Tan, Hany Hassan, Arul Menezes, Tong Xiao, Jiang Bian and JingBo Zhu
              <br>
              <!-- <em>61th Annual Meeting of the Association for Computational Linguistics (<strong>Findings of ACL</strong>)</em>, 2023  -->
              <em> In progress, comming soon. </em>
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2305.19835">[pdf]</a> / [<a href="">code</a>]
              <p></p>
              <p>
                We encourage the model to deliberate by proposing a novel Deliberate then Generate (DTG) prompting framework, which consists of error detection instructions and candidates that may contain errors. DTG is a simple yet effective technique that can be applied to various text generation tasks with minimal modifications. We conduct extensive experiments on 20+ datasets across 7 text generation tasks, including summarization, translation, dialogue, and more. We show that DTG consistently outperforms existing prompting methods and achieves state-of-the-art performance on multiple text generation tasks.
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/ACL2023_tm.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle> Augmenting Large Language Model Translators via Translation Memories</papertitle>
              <!-- </a> -->
              <br>
              Yongyu Mu, Abudurexiti Reheman, Zhiquan Cao, Yuchun Fan, <strong>Bei Li</strong>, Yinqiao Li, Tong Xiao, Chunliang Zhang and Jingbo Zhu
              <br>
              <em>61th Annual Meeting of the Association for Computational Linguistics (<strong>Findings of ACL</strong>)</em>, 2023 
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2305.17367">[pdf]</a> / [<a href="">code</a>]
              <p></p>
              <p>
                In-context learning (ICL) augments the capabilities of large language models (LLMs) in various downstream tasks by leveraging input and output exemplars. This paper explores the use of translation memory (TM) as a form of prompting to aid LLMs in machine translation tasks. Notably, the LLM's inherent ability to comprehend these prompts significantly bolsters the use of TM. Experimental results indicate that incorporating TM considerably enhances the translation proficiency of the LLM, elevating its BLEU score to levels commensurate with state-of-the-art neural machine translation systems.
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/ACL2023_manager.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning</papertitle>
              <!-- </a> -->
              <br>
              Xiao Xu, <strong>Bei Li</strong>, Chenfei Wu, Shao-Yen Tseng, Anahita Bhiwandiwalla, Shachar Rosenman, Vasudev Lal, Wanxiang Che and Nan Duan
              <br>
              <em>61th Annual Meeting of the Association for Computational Linguistics (<strong>ACL, Oral</strong>)</em>, 2023 
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2306.00103">[pdf]</a> / [<a href="">code</a>]
              <p></p>
              <p>
                We propose ManagerTower, a novel Vision-Language model architecture that gathers and combines the insights of pre-trained uni-modal experts at different levels. The managers introduced in each cross-modal layer can adaptively aggregate uni-modal semantic knowledge to facilitate more comprehensive cross-modal alignment and fusion. ManagerTower outperforms prior work.
              </p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/ACL2023.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>TranSFormer: Slow-Fast Transformer for Machine Translation</papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li</strong>,
              Yi Jing, Xu Tan, Zhen Xing, Tong Xiao and Jingbo Zhu
              <br>
              <em>61th Annual Meeting of the Association for Computational Linguistics (<strong>Findings of ACL</strong>)</em>, 2023 
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://arxiv.org/abs/2305.16982">[pdf]</a> / [<a href="">code</a>]
              <p></p>
              <p>
                Building upon our previous ICML work, we refine the extraction of fine-grained character-level features by developing a multiscale Transformer model with a two-branch architecture. The Slow-Fast framework effectively mitigates the computational overhead associated with capturing long-term dependencies among character-level sequences, while employing a cross-granularity attention mechanism to learn interactions between the fast and slow branches. Comprehensive experiments conducted on multiple machine translation benchmarks attest to the efficacy of our proposed TranSFormer model.
              </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/umst.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Learning Multiscale Transformer Models for Sequence Generation</papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li</strong>,
              Tong Zheng, Yi Jing, Chengbo Jiao, Tong Xiaoand Jingbo Zhu
              <br>
              <em>International Conference on Machine Learning (<strong>ICML, Spotlight</strong>)</em>, 2022  
              <br>
							<!-- <a href="#">[pdf](not aviable)</a> / 
							<a href="#">[code](not aviable)</a>  -->
							<a href="https://proceedings.mlr.press/v162/li22ac/li22ac.pdf">[pdf]</a> / [<a href="https://github.com/libeineu/UMST">code</a>]
              <p></p>
              <p>We re-define the concept of scale for NLP, including scales of sub-word, word and phrase. Our intention is to leverage the word boundaries and phrase-level prior knowledge to compensate for the sub-word features. Then we establish the relationships among different scales, resulting in builting a multiscale Transformer model.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/multimodal.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>On Vision Features in Multimodal Machine Translation</papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li</strong>,
              Chuanhao Lv, Zefan Zhou, Tao Zhou, Tong Xiao, Anxiang Ma and Jingbo Zhu
              <br>
              <em>60th Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>)</em>, 2022  
              <br>
							<a href="https://aclanthology.org/2022.acl-long.438.pdf">[pdf]</a> / [<a href="https://github.com/libeineu/fairseq_mmt">code</a>]
							<!-- <a href="#">[code](not aviable)</a>  -->
              <p></p>
              <p> This work investigates the effect of vision features in multimodal machine translation (MMT) scenarios. We proposed three probing tasks to evaluate MMT systems which can help the following researchers. The main contribution is to reveal the importance of strong vision features.</p>
            </td>
          </tr>
				
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/ode_transformer.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>ODE Transformer: An Ordinary Differential Equation-Inspired Model for Sequence Generation
                  </papertitle>
              <!-- </a> -->
              <br> 
              <strong>Bei Li</strong>,
              Quan Du, Tao Zhou, Yi Jing, Shuhan Zhou, Xin Zeng, Tong Xiao,and Jingbo Zhu
              <br>
              <em>60th Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>)</em>, 2022  
              <br> 
              [<a href="https://aclanthology.org/2022.acl-long.571.pdf">pdf</a>] / [<a href="https://github.com/libeineu/ODE-Transformer">code</a>]
              <p></p>
              <p>This work attempts to further enhance the standard sequence-level KD method by taking full advantage of the teacher parameters and generate the parameters for student.
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/acl2021.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Weight Distillation: Transferring the Knowledge in Neural Network Parameters
                  </papertitle>
              <!-- </a> -->
              <br> 
              Ye Lin, Yanyang Li, Ziyang Wang, <strong>Bei Li</strong>, Quan Du, Tong Xiao, Jingbo Zhu
              <br>
              <em>59th Annual Meeting of the Association for Computational Linguistics (<strong>ACL, Oral</strong>)</em>, 2021  
              <br> 
              [<a href="https://aclanthology.org/2021.acl-long.162.pdf">pdf</a>] / [code]
              <p></p>
              <p>This work establishes the relationship between ODE and the design of Transformer architecture. We also redesign the Transformer architecture inspired by the lower truncation error achieved by high-order solvers in ODE. ODE Transformer can deliver much better translation performance within the same model capacity. Experimental results on three sequence generation tasks demonstrate the effectiveness.
              </p>
            </td>
          </tr>
 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/GPKD.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Learning Light-Weight Translation Models from Deep Transformer
                  </papertitle>
              <!-- </a> -->
              <br> 
              <strong>Bei Li</strong>,
              Ziyang Wang, Hui Liu, Quan Du, Tong Xiao, Chunliang Zhang, Jingbo Zhu
              <br>
              <em>Thirty-Fifth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2021  
              <br> 
              [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17561">pdf</a>] / [<a href="https://github.com/libeineu/GPKD">code</a>]
              <p></p>
              <p>This work attempts to learn a light-weight translation model from a deep Transformer teacher network. It introduces a group-permutation based knowledge distillation method to compressing a strong deep Transformer teacher into a much shallower counterpart with a minor BLEU degradation. Furthermore, to enhance the performance of the teacher network, we also propose a skipping sub-layer regularization training method to randomly omit some sub-layers vertically. Both methods can be well applicable into the teacher training process.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/sdt.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Shallow-to-Deep Training for Neural Machine Translation
                  </papertitle>
              <!-- </a> -->
              <br> 
              <strong>Bei Li</strong>,
              Ziyang Wang, Hui Liu, Yufan Jiang, Quan Du, Tong Xiao, Huizhen Wang, Jingbo Zhu
              <br>
              <em>The 2020 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>)</em>, 2020  
              <br> 
              [<a href="https://aclanthology.org/2020.emnlp-main.72.pdf">pdf</a>] / [<a href="https://github.com/libeineu/SDT-Training">code</a>]
              <p></p>
              <p>Deep Transformer systems have been widely investigated in the MT community recently. However, with the model going deeper, a crucial challenge is the huge memory cost and extremely long training time. We investigate the behavior of trained systems and find that adjacent layers behave similarly. Thus, we proposed a shallow-to-deep training method instead of learning from scratch which speeds up the training process up to 1.5 times with no loss in BLEU.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/context-aware.png' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine Translation
                  </papertitle>
              <!-- </a> -->
              <br> 
              <strong>Bei Li</strong>,
              Hui Liu, Ziyang Wang, Yufan Jiang, Tong Xiao, Jingbo Zhu, Tongran Liu, Changliang Li
              <br>
              <em>58th Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>)</em>, 2020  
              <br> 
              [<a href="https://www.aclweb.org/anthology/2020.acl-main.322.pdf">pdf</a>] / [<a href="https://github.com/libeineu/Context-Aware">code</a>]
              <p></p>
              <p>We investigate a general-used multi-encoder framework on document-level machine translation task. It utilizes an additional context-encoder to capture the relationship between the current sentence and its contextual information. However, through specially designed context inputs, we find that the context-encoder acts more like a noise generator instead of encoding the contextual information, which is similar with dropout.Especially when we turn off the context-encoder during inference, there is even slight improvements in terms of BLEU score.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/dlcl.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>Learning deep transformer models for machine translation
                  </papertitle>
              <!-- </a> -->
              <br> 
              Qiang Wang,
              <strong>Bei Li</strong>,
              Tong Xiao, Jingbo Zhu, Changliang Li, Derek F Wong, Lidia S Chao 
              <br>
              <em>57th Annual Meeting of the Association for Computational Linguistics (<strong>ACL, Oral</strong>)</em>, 2019  
              <br> 
              [<a href="https://aclanthology.org/P19-1176.pdf">pdf</a>] / [<a href="https://github.com/wangqiangneu/dlcl">code</a>]
              <p></p>
              <p>It studies deep encoders in Transformer and mathematically explains the importance of the location of layer normalization for deep models. It also proposes a novel connection schema to successfully train a 30-layer Transformer system, which is the deepest encoder at that time. While, it is one of the most high cited NMT papers.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <img src='images/wmt19.jpg' width="160" mar>
              </div>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<!-- <a href="#"> -->
                <papertitle>The niutrans machine translation systems for wmt19
                  </papertitle>
              <!-- </a> -->
              <br>
              <strong>Bei Li</strong>,
              Yinqiao Li, Chen Xu, Ye Lin, Jiqiang Liu, Hui Liu, Ziyang Wang, Yuhao Zhang, Nuo Xu, Zeyang Wang, Kai Feng, Hexuan Chen, Tengbo Liu, Yanyang Li, Qiang Wang, Tong Xiao, Jingbo Zhu
              <br>
              <em>Fourth Conference on Machine Translation (<strong>WMT, Workshop of ACL</strong>)</em>, 2019 
              <br>
							<a href="https://aclanthology.org/W19-5325.pdf">[pdf]</a> / 
							<!-- <a href="#">[code](not aviable)</a>  -->
              [code]
              <p></p>
              <p>It describes the submission of the NiuTrans systems for WMT2019 on both supervised and unsupervised tasks, including 13 language directions. This paper shows the details about model architectures, data augmentation methods, ensemble knowledge distillation and system combination strategies.
              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Honors & Awards</heading>
            <ul style="list-style-type:none">
              <p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
              
              <li style="margin-bottom:5px">
                Outstanding Doctoral Dissertation (10 persons/year), CIPS of China. <div style="float:right; text-align:right">2024</div>
              </li>
                
              <li style="margin-bottom:5px">
                  Baidu Scholarship Finalist. <div style="float:right; text-align:right">2022</div>
              </li>
              
              <li style="margin-bottom:5px">
                National Scholarship (PH.D). <div style="float:right; text-align:right">2022</div>
              </li>
              
              <li style="margin-bottom:5px">
                Top Ten Graduate students of Northeastern University (The May 4th medal). <div style="float:right; text-align:right">2022</div>
              </li>

              <li style="margin-bottom:5px">
                National Scholarship (PH.D). <div style="float:right; text-align:right">2021</div>
              </li>

              <li style="margin-bottom:5px">
                Outstanding Reviewers of EMNLP2021. <div style="float:right; text-align:right">2021</div>
              </li>

              <li style="margin-bottom:5px">
                1st Rank in Chinese-English in terms of human-evaluation on WMT21. <div style="float:right; text-align:right">2021</div>
              </li>

              <li style="margin-bottom:5px">
                The Excellent Master thesis of Liaoning Province. <div style="float:right; text-align:right">2020</div>
              </li>

              <li style="margin-bottom:5px">
                The Excellent Master Graduate of Liao Ning Province. <div style="float:right; text-align:right">2020</div>
              </li>

              <li style="margin-bottom:5px">
                The Excellent Master Graduate of Northeastern. <div style="float:right; text-align:right">2020</div>
              </li>

              <li style="margin-bottom:5px">
                1st Rank in Japanese-English news translation in terms of human-evaluation on WMT20. <div style="float:right; text-align:right">2020</div>
              </li>
              
              <li style="margin-bottom:5px">
                National Scholarship (Master). <div style="float:right; text-align:right">2019</div>
              </li>

              <li style="margin-bottom:5px">
                1st Rank in 3 news translation in terms of auto-evaluation on WMT19. <div style="float:right; text-align:right">2019</div>
              </li>

              <li style="margin-bottom:5px">
                2nd Rank in 3 news translation in terms of auto-evaluation on WMT19. <div style="float:right; text-align:right">2019</div>
              </li>

              <li style="margin-bottom:5px">
                National Scholarship (Master, Rank 1/230). <div style="float:right; text-align:right">2018</div>
              </li>
              
              <li style="margin-bottom:5px">
                The Excellent Graduate of Shenyang. <div style="float:right; text-align:right">2018</div>
              </li>
              
              <li style="margin-bottom:5px">
                1st Rank in Chinese-English news translation in terms of human-evaluation on WMT18. <div style="float:right; text-align:right">2018</div>
              </li>
              <li style="margin-bottom:5px">
                2nd Rank in English-Chinese news translation in terms of auto-evaluation on WMT18. <div style="float:right; text-align:right">2018</div>
              </li>


              <!-- <li style="margin-bottom:5px"><a href="https://challenge.ai.mgtv.com/home">MangoTV</a> International audio and video algorithm competition <strong> (Rank 6/193)</strong>. <div style="float:right; text-align:right">2021</div> -->
              </li>
              <br>
              </p>
              </ul>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <heading>Intern Experiences</heading>
          <tr>
            <td  style="padding:20px;width:35%;vertical-align:middle">
              <img width="160" src="./images/weiruan.png">
            </td>
            <td style="margin-left:20px;width:65%;vertical-align:middle">
              <div >
                Research Intern, MicroSoft Research Asia, Natural Language Computing
              </div>
              May. 2022 - Dec. 2022 <br>
              Advisor: Chenfei Wu <br>
              Text-to-Image Generation, Diffusion Models, Multimodal Modeling
            </td>
          </tr>

          <tr>
            <td  style="padding:20px;width:35%;vertical-align:middle">
              <img width="160" src="./images/weiruan.png">
            </td>
            <td style="margin-left:20px;width:65%;vertical-align:middle">
              <div >
                Research Intern, MicroSoft Research Asia, Machine Learning
              </div>
              Dec. 2022 - Nov. 2023 <br>
              Advisor: Xu Tan, Rui Wang <br>
              Machine Translation, Ordinary Differential Equation, Large Language Models
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Professional activities</heading>
            <ul style="list-style-type:none">
              <p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
              <li >
                Conference Reviewer for ACL, EMNLP, ICML, ICLR, Neurips, AAAI, IJCAI, NAACL, COLING, EACL
              </li>
              <br>
              </p>
              </ul>

        </tbody></table>

				
     
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
             
                <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  &copy; Bei Li | Last updated: Nov. 2023.</p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
